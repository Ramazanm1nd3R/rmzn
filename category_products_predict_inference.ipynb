{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a18e612",
   "metadata": {},
   "source": [
    "Two–stage ONNX inference:\n",
    "  1) category  → 2) product-within-category\n",
    "Assumes directory layout:\n",
    "\n",
    "models/\n",
    "├── tokenizer/                     (save_pretrained)\n",
    "├── category_model/\n",
    "│   ├── tokenizer/\n",
    "│   ├── model_quantized.onnx\n",
    "│   └── label_encoder.pkl\n",
    "├── cards/\n",
    "│   ├── model_quantized.onnx\n",
    "│   └── label_encoder.pkl\n",
    "├── deposits/\n",
    "│   └── ...\n",
    "└── …\n",
    "\n",
    "Если под-модель для категории отсутствует, возвращается \"<category>_common\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32631a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.22.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: scikit-learn in d:\\programs\\miniconda\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy in d:\\programs\\miniconda\\lib\\site-packages (1.26.4)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: packaging in d:\\programs\\miniconda\\lib\\site-packages (from onnxruntime) (24.1)\n",
      "Requirement already satisfied: protobuf in d:\\programs\\miniconda\\lib\\site-packages (from onnxruntime) (4.25.3)\n",
      "Requirement already satisfied: sympy in d:\\programs\\miniconda\\lib\\site-packages (from onnxruntime) (1.13.2)\n",
      "Requirement already satisfied: filelock in d:\\programs\\miniconda\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.32.6-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\programs\\miniconda\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\programs\\miniconda\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in d:\\programs\\miniconda\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\programs\\miniconda\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\programs\\miniconda\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\programs\\miniconda\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\programs\\miniconda\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\programs\\miniconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\programs\\miniconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in d:\\programs\\miniconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\programs\\miniconda\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programs\\miniconda\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\programs\\miniconda\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programs\\miniconda\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\programs\\miniconda\\lib\\site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime)\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading onnxruntime-1.22.0-cp312-cp312-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.7 MB 541.6 kB/s eta 0:00:23\n",
      "   - -------------------------------------- 0.5/12.7 MB 541.6 kB/s eta 0:00:23\n",
      "   -- ------------------------------------- 0.8/12.7 MB 559.5 kB/s eta 0:00:22\n",
      "   -- ------------------------------------- 0.8/12.7 MB 559.5 kB/s eta 0:00:22\n",
      "   --- ------------------------------------ 1.0/12.7 MB 592.2 kB/s eta 0:00:20\n",
      "   --- ------------------------------------ 1.0/12.7 MB 592.2 kB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 1.3/12.7 MB 604.7 kB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 1.3/12.7 MB 604.7 kB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 1.3/12.7 MB 604.7 kB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 1.6/12.7 MB 582.5 kB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 1.6/12.7 MB 582.5 kB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 1.8/12.7 MB 572.0 kB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 1.8/12.7 MB 572.0 kB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 1.8/12.7 MB 572.0 kB/s eta 0:00:19\n",
      "   ------ --------------------------------- 2.1/12.7 MB 564.6 kB/s eta 0:00:19\n",
      "   ------ --------------------------------- 2.1/12.7 MB 564.6 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 2.4/12.7 MB 561.6 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 2.4/12.7 MB 561.6 kB/s eta 0:00:19\n",
      "   -------- ------------------------------- 2.6/12.7 MB 565.5 kB/s eta 0:00:18\n",
      "   -------- ------------------------------- 2.6/12.7 MB 565.5 kB/s eta 0:00:18\n",
      "   --------- ------------------------------ 2.9/12.7 MB 566.8 kB/s eta 0:00:18\n",
      "   --------- ------------------------------ 2.9/12.7 MB 566.8 kB/s eta 0:00:18\n",
      "   --------- ------------------------------ 2.9/12.7 MB 566.8 kB/s eta 0:00:18\n",
      "   --------- ------------------------------ 3.1/12.7 MB 555.9 kB/s eta 0:00:18\n",
      "   --------- ------------------------------ 3.1/12.7 MB 555.9 kB/s eta 0:00:18\n",
      "   --------- ------------------------------ 3.1/12.7 MB 555.9 kB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 3.4/12.7 MB 539.8 kB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 3.4/12.7 MB 539.8 kB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 3.4/12.7 MB 539.8 kB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 3.7/12.7 MB 532.0 kB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 3.7/12.7 MB 532.0 kB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 3.7/12.7 MB 532.0 kB/s eta 0:00:17\n",
      "   ------------ --------------------------- 3.9/12.7 MB 527.8 kB/s eta 0:00:17\n",
      "   ------------ --------------------------- 3.9/12.7 MB 527.8 kB/s eta 0:00:17\n",
      "   ------------- -------------------------- 4.2/12.7 MB 527.6 kB/s eta 0:00:17\n",
      "   ------------- -------------------------- 4.2/12.7 MB 527.6 kB/s eta 0:00:17\n",
      "   -------------- ------------------------- 4.5/12.7 MB 526.4 kB/s eta 0:00:16\n",
      "   -------------- ------------------------- 4.5/12.7 MB 526.4 kB/s eta 0:00:16\n",
      "   -------------- ------------------------- 4.5/12.7 MB 526.4 kB/s eta 0:00:16\n",
      "   -------------- ------------------------- 4.7/12.7 MB 521.4 kB/s eta 0:00:16\n",
      "   -------------- ------------------------- 4.7/12.7 MB 521.4 kB/s eta 0:00:16\n",
      "   -------------- ------------------------- 4.7/12.7 MB 521.4 kB/s eta 0:00:16\n",
      "   --------------- ------------------------ 5.0/12.7 MB 520.7 kB/s eta 0:00:15\n",
      "   --------------- ------------------------ 5.0/12.7 MB 520.7 kB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 5.2/12.7 MB 522.6 kB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 5.2/12.7 MB 522.6 kB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 5.5/12.7 MB 524.3 kB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 5.5/12.7 MB 524.3 kB/s eta 0:00:14\n",
      "   ------------------ --------------------- 5.8/12.7 MB 527.5 kB/s eta 0:00:14\n",
      "   ------------------ --------------------- 5.8/12.7 MB 527.5 kB/s eta 0:00:14\n",
      "   ------------------ --------------------- 5.8/12.7 MB 527.5 kB/s eta 0:00:14\n",
      "   ------------------- -------------------- 6.0/12.7 MB 529.6 kB/s eta 0:00:13\n",
      "   ------------------- -------------------- 6.0/12.7 MB 529.6 kB/s eta 0:00:13\n",
      "   ------------------- -------------------- 6.3/12.7 MB 533.0 kB/s eta 0:00:13\n",
      "   -------------------- ------------------- 6.6/12.7 MB 537.6 kB/s eta 0:00:12\n",
      "   -------------------- ------------------- 6.6/12.7 MB 537.6 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 6.8/12.7 MB 542.6 kB/s eta 0:00:11\n",
      "   --------------------- ------------------ 6.8/12.7 MB 542.6 kB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 7.1/12.7 MB 547.3 kB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 7.1/12.7 MB 547.3 kB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 7.3/12.7 MB 549.1 kB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 7.3/12.7 MB 549.1 kB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 7.6/12.7 MB 552.7 kB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 7.6/12.7 MB 552.7 kB/s eta 0:00:10\n",
      "   ------------------------ --------------- 7.9/12.7 MB 554.8 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 7.9/12.7 MB 554.8 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 8.1/12.7 MB 558.0 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 8.1/12.7 MB 558.0 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 8.1/12.7 MB 558.0 kB/s eta 0:00:09\n",
      "   -------------------------- ------------- 8.4/12.7 MB 554.5 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 8.4/12.7 MB 554.5 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 8.4/12.7 MB 554.5 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 8.7/12.7 MB 550.6 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 8.7/12.7 MB 550.6 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 8.7/12.7 MB 550.6 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 8.9/12.7 MB 540.7 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 8.9/12.7 MB 540.7 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 8.9/12.7 MB 540.7 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 8.9/12.7 MB 540.7 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 8.9/12.7 MB 540.7 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 9.2/12.7 MB 522.8 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 9.2/12.7 MB 522.8 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 9.2/12.7 MB 522.8 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 9.2/12.7 MB 522.8 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 9.2/12.7 MB 522.8 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 9.4/12.7 MB 507.1 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 9.4/12.7 MB 507.1 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 9.4/12.7 MB 507.1 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 9.4/12.7 MB 507.1 kB/s eta 0:00:07\n",
      "   ------------------------------ --------- 9.7/12.7 MB 499.2 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 9.7/12.7 MB 499.2 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 9.7/12.7 MB 499.2 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 9.7/12.7 MB 499.2 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 10.0/12.7 MB 495.0 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 10.0/12.7 MB 495.0 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 10.0/12.7 MB 495.0 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 10.2/12.7 MB 493.5 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 10.2/12.7 MB 493.5 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 10.5/12.7 MB 492.7 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 10.5/12.7 MB 492.7 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 10.5/12.7 MB 492.7 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 10.7/12.7 MB 493.4 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 10.7/12.7 MB 493.4 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 11.0/12.7 MB 494.9 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 11.0/12.7 MB 494.9 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 11.3/12.7 MB 497.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 11.3/12.7 MB 497.3 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 11.5/12.7 MB 499.6 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 11.5/12.7 MB 499.6 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 11.8/12.7 MB 502.2 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 11.8/12.7 MB 502.2 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 12.1/12.7 MB 505.7 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 12.1/12.7 MB 505.7 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 12.3/12.7 MB 508.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.7 MB 508.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.7 MB 510.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 510.0 kB/s eta 0:00:00\n",
      "Using cached transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "Downloading huggingface_hub-0.32.6-py3-none-any.whl (512 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: flatbuffers, safetensors, pyreadline3, humanfriendly, huggingface-hub, tokenizers, coloredlogs, transformers, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-25.2.10 huggingface-hub-0.32.6 humanfriendly-10.0 onnxruntime-1.22.0 pyreadline3-3.5.4 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.52.4\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime transformers scikit-learn numpy onnx torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c2ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import joblib\n",
    "import onnxruntime as ort\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ecafbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Укажи путь до models/\n",
    "MODELS_DIR     = Path(\"models\")  # или полный путь\n",
    "\n",
    "TOK_DIR        = MODELS_DIR / \"tokenizer\"\n",
    "CAT_DIR        = MODELS_DIR / \"category_model\"\n",
    "CAT_TOK_DIR    = CAT_DIR / \"tokenizer\"\n",
    "CAT_MODEL_PATH = CAT_DIR / \"model_quantized.onnx\"\n",
    "CAT_LABELS     = CAT_DIR / \"label_encoder.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e37d50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoStageClassifier:\n",
    "    def __init__(self):\n",
    "        self.cat_tok = AutoTokenizer.from_pretrained(CAT_TOK_DIR)\n",
    "        self.prod_tok = AutoTokenizer.from_pretrained(TOK_DIR)\n",
    "        self.cat_sess = ort.InferenceSession(str(CAT_MODEL_PATH))\n",
    "        self.cat_enc = joblib.load(CAT_LABELS)\n",
    "        self.prod_cache: dict[str, tuple[ort.InferenceSession, joblib]] = {}\n",
    "\n",
    "    def _run(self, sess, text, tokenizer, max_len=128):\n",
    "        enc = tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"np\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=max_len\n",
    "        )\n",
    "        return sess.run([\"logits\"], {\n",
    "            \"input_ids\": enc[\"input_ids\"].astype(\"int64\"),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].astype(\"int64\")\n",
    "        })[0]\n",
    "\n",
    "    def predict(self, text: str) -> dict:\n",
    "        cat_logits = self._run(self.cat_sess, text, tokenizer=self.cat_tok)\n",
    "        cat_id = int(np.argmax(cat_logits, axis=1)[0])\n",
    "        category = self.cat_enc.inverse_transform([cat_id])[0]\n",
    "\n",
    "        folder = category.lower().replace(\" \", \"_\")\n",
    "        folder_path = MODELS_DIR / folder\n",
    "\n",
    "        if not folder_path.exists():\n",
    "            return {\"category\": category, \"product\": f\"{folder}_common\"}\n",
    "\n",
    "        if folder not in self.prod_cache:\n",
    "            model_path = folder_path / \"model_quantized.onnx\"\n",
    "            labels_path = folder_path / \"label_encoder.pkl\"\n",
    "            if not model_path.exists() or not labels_path.exists():\n",
    "                return {\"category\": category, \"product\": f\"{folder}_common\"}\n",
    "            sess = ort.InferenceSession(str(model_path))\n",
    "            enc = joblib.load(labels_path)\n",
    "            self.prod_cache[folder] = (sess, enc)\n",
    "\n",
    "        sess, enc = self.prod_cache[folder]\n",
    "        prod_logits = self._run(sess, text, tokenizer=self.prod_tok)\n",
    "        prod_id = int(np.argmax(prod_logits, axis=1)[0])\n",
    "        product = enc.inverse_transform([prod_id])[0]\n",
    "\n",
    "        return {\"category\": category, \"product\": product}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e6f66d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\MiniConda\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.6.1 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = TwoStageClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2397d80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟢 как заказать карту?\n",
      "→ {'category': 'Cards', 'product': 'cards_common'}\n",
      "\n",
      "🟢 можно ли открыть вклад в приложении?\n",
      "→ {'category': 'Deposits', 'product': 'deposits_common'}\n",
      "\n",
      "🟢 хочу оплатить штраф\n",
      "→ {'category': 'Other', 'product': 'operator'}\n",
      "\n",
      "🟢 Работает ли QR оплата для коммунальных услуг?\n",
      "→ {'category': 'Payments', 'product': 'payments_common'}\n",
      "\n",
      "🟢 можно ли взять автокредит?\n",
      "→ {'category': 'Avtokredit', 'product': 'avtokredit_common'}\n",
      "\n",
      "🟢 как взять кредит под залог недвижимости\n",
      "→ {'category': 'Zalogovoe', 'product': 'zalog_nedvizhimosti'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    \"как заказать карту?\",\n",
    "    \"можно ли открыть вклад в приложении?\",\n",
    "    \"хочу оплатить штраф\",\n",
    "    \"Работает ли QR оплата для коммунальных услуг?\",\n",
    "    \"можно ли взять автокредит?\",\n",
    "    \"как взять кредит под залог недвижимости\"\n",
    "]\n",
    "\n",
    "for text in examples:\n",
    "    result = clf.predict(text)\n",
    "    print(f\"🟢 {text}\\n→ {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524623b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference.py\n",
    "\n",
    "from pathlib import Path\n",
    "import argparse, joblib, numpy as np, onnxruntime as ort\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "# ----------------- ПУТИ К ФАЙЛАМ -----------------\n",
    "MODELS_DIR     = Path(__file__).resolve().parent / \"models\"\n",
    "TOK_DIR        = MODELS_DIR / \"tokenizer\"                      # общий для продуктов\n",
    "CAT_DIR        = MODELS_DIR / \"category_model\"\n",
    "CAT_TOK_DIR    = CAT_DIR / \"tokenizer\"                         # токенайзер для категорий\n",
    "CAT_MODEL_PATH = CAT_DIR / \"model_quantized.onnx\"\n",
    "CAT_LABELS     = CAT_DIR / \"label_encoder.pkl\"\n",
    "\n",
    "\n",
    "class TwoStageClassifier:\n",
    "    def __init__(self):\n",
    "        # 🔹 Токенизаторы\n",
    "        self.cat_tok = AutoTokenizer.from_pretrained(CAT_TOK_DIR)  # категоризация\n",
    "        self.prod_tok = AutoTokenizer.from_pretrained(TOK_DIR)     # продукты\n",
    "\n",
    "        # 🔹 ONNX сессия + LabelEncoder (категории)\n",
    "        self.cat_sess = ort.InferenceSession(str(CAT_MODEL_PATH))\n",
    "        self.cat_enc = joblib.load(CAT_LABELS)\n",
    "\n",
    "        # 🔹 кеш {folder → (session, encoder)}\n",
    "        self.prod_cache: dict[str, tuple[ort.InferenceSession, joblib]] = {}\n",
    "\n",
    "    def _run(self, sess, text, tokenizer, max_len=128):\n",
    "        enc = tokenizer(text, return_tensors=\"np\", padding=\"max_length\",\n",
    "                        truncation=True, max_length=max_len)\n",
    "        return sess.run([\"logits\"], {\n",
    "            \"input_ids\": enc[\"input_ids\"],\n",
    "            \"attention_mask\": enc[\"attention_mask\"]\n",
    "        })[0]\n",
    "\n",
    "    def predict(self, text: str) -> dict:\n",
    "        # === ① Категория ===\n",
    "        cat_logits = self._run(self.cat_sess, text, tokenizer=self.cat_tok)\n",
    "        cat_id = int(np.argmax(cat_logits, axis=1)[0])\n",
    "        category = self.cat_enc.inverse_transform([cat_id])[0]\n",
    "\n",
    "        folder = category.lower().replace(\" \", \"_\")\n",
    "        folder_path = MODELS_DIR / folder\n",
    "\n",
    "        # === ② Продукт ===\n",
    "        if not folder_path.exists():\n",
    "            return {\"category\": category, \"product\": f\"{folder}_common\"}\n",
    "\n",
    "        if folder not in self.prod_cache:\n",
    "            model_path = folder_path / \"model_quantized.onnx\"\n",
    "            labels_path = folder_path / \"label_encoder.pkl\"\n",
    "            if not model_path.exists() or not labels_path.exists():\n",
    "                return {\"category\": category, \"product\": f\"{folder}_common\"}\n",
    "\n",
    "            sess = ort.InferenceSession(str(model_path))\n",
    "            enc = joblib.load(labels_path)\n",
    "            self.prod_cache[folder] = (sess, enc)\n",
    "\n",
    "        sess, enc = self.prod_cache[folder]\n",
    "        prod_logits = self._run(sess, text, tokenizer=self.prod_tok)\n",
    "        prod_id = int(np.argmax(prod_logits, axis=1)[0])\n",
    "        product = enc.inverse_transform([prod_id])[0]\n",
    "\n",
    "        return {\"category\": category, \"product\": product}\n",
    "\n",
    "\n",
    "# ----------------- CLI запуск -----------------\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Two-stage ONNX classifier\")\n",
    "    parser.add_argument(\"text\", nargs=\"*\", help=\"Input query\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.text:\n",
    "        query = \" \".join(args.text)\n",
    "    else:\n",
    "        query = input(\"Введите запрос: \")\n",
    "\n",
    "    print(f\"[INFO] Ввод: {query}\")\n",
    "\n",
    "    clf = TwoStageClassifier()\n",
    "    result = clf.predict(query)\n",
    "\n",
    "    if not result:\n",
    "        print(\"[WARNING] Модель не вернула результат\")\n",
    "    else:\n",
    "        print(\"[RESULT]\", result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
