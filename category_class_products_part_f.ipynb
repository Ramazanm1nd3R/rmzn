{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EAkPclGlZ8Lu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('faq_channels_et_products_train_dataset_verified.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Gp0VlIGueyLV"
      },
      "outputs": [],
      "source": [
        "manual_map = {\n",
        "    'Smart QR': 'SmartQR',\n",
        "    'smart qr': 'SmartQR'\n",
        "}\n",
        "\n",
        "df['right_category'] = df['right_category'].replace(manual_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hzPBMPJ7e0XQ"
      },
      "outputs": [],
      "source": [
        "df = df[['text', 'right_category', 'right_product']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "696NUZeIe5uc"
      },
      "outputs": [],
      "source": [
        "df = df.drop_duplicates(subset='text', keep='first')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H5gbtR5Ge9DA"
      },
      "outputs": [],
      "source": [
        "df = df[df[\"right_category\"] != \"Investitsii_v_bcc_kz\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xmOfl_pfdQao"
      },
      "outputs": [],
      "source": [
        "def normalize_label(label):\n",
        "    return str(label).strip().lower().replace(\" \", \"_\")\n",
        "\n",
        "df[\"right_product\"] = df[\"right_product\"].astype(str).apply(normalize_label)\n",
        "df[\"right_category\"] = df[\"right_category\"].astype(str).apply(normalize_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "411jWQdZ4vXy"
      },
      "outputs": [],
      "source": [
        "# Очистка от нестроковых значений\n",
        "df[\"text\"] = df[\"text\"].astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht7jQNqufCQc"
      },
      "source": [
        "# *Модели*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8im8MEzhntd4",
        "outputId": "3fce4d96-d0a1-43ff-ad64-7c0273536f5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.14.0)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.18.0\n"
          ]
        }
      ],
      "source": [
        "pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlLVt0T2BzR7",
        "outputId": "b6b99eeb-6f1e-433f-ad74-808f6409a3e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.22.0\n"
          ]
        }
      ],
      "source": [
        "pip install onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Gd1vWUaeQjU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "k3E4yO4icjt-"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MODEL_NAME = \"intfloat/multilingual-e5-small\"\n",
        "BASE_SAVE_DIR = \"saved_models\"\n",
        "\n",
        "# Убедимся, что папка существует\n",
        "os.makedirs(BASE_SAVE_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LtjQXduw4-ji"
      },
      "outputs": [],
      "source": [
        "# === Группируем по категориям ===\n",
        "category_names = df[\"right_category\"].unique()\n",
        "category_groups = {cat: df[df[\"right_category\"] == cat].copy() for cat in category_names}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TLky5dp8cqsg"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "class ProductDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=256):\n",
        "        self.texts = texts.reset_index(drop=True).astype(str)\n",
        "        self.labels = labels.reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mSgFl0zSif_5"
      },
      "outputs": [],
      "source": [
        "class E5ProductClassifier(nn.Module):\n",
        "    def __init__(self, model_name, num_classes):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        self.classifier = nn.Linear(self.encoder.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_token = out.last_hidden_state[:, 0, :]\n",
        "        return self.classifier(cls_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsX2LsVe6an5"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 3\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Корневая директория для сохранения\n",
        "os.makedirs(BASE_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Сохраняем токенизатор один раз\n",
        "tokenizer_save_dir = os.path.join(BASE_SAVE_DIR, \"tokenizer\")\n",
        "if not os.path.exists(tokenizer_save_dir):\n",
        "    tokenizer.save_pretrained(tokenizer_save_dir)\n",
        "    print(f\"Токенизатор сохранён в {tokenizer_save_dir}\")\n",
        "\n",
        "for category, sub_df in category_groups.items():\n",
        "    category_dir = os.path.join(BASE_SAVE_DIR, category.replace(\" \", \"_\"))\n",
        "    if os.path.exists(os.path.join(category_dir, \"model_quantized.onnx\")):\n",
        "        print(f\"Пропущена категория {category}, квантизированная модель уже существует.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nОбучение модели для категории: {category} ({len(sub_df)} записей)\")\n",
        "    os.makedirs(category_dir, exist_ok=True)\n",
        "\n",
        "    sub_df = sub_df.copy().reset_index(drop=True)\n",
        "\n",
        "    # === LabelEncoder ===\n",
        "    le = LabelEncoder()\n",
        "    sub_df[\"product_label\"] = le.fit_transform(sub_df[\"right_product\"])\n",
        "    joblib.dump(le, os.path.join(category_dir, \"label_encoder.pkl\"))\n",
        "\n",
        "    # Удалим редкие классы\n",
        "    min_class_size = 2\n",
        "    class_counts = sub_df[\"product_label\"].value_counts()\n",
        "    valid_classes = class_counts[class_counts >= min_class_size].index\n",
        "    sub_df = sub_df[sub_df[\"product_label\"].isin(valid_classes)].reset_index(drop=True)\n",
        "\n",
        "    if sub_df[\"product_label\"].nunique() < 2:\n",
        "        print(f\"Пропущена категория {category} — слишком мало уникальных классов после фильтрации.\")\n",
        "        continue\n",
        "\n",
        "    # Подготовка данных\n",
        "    X = sub_df[\"text\"]\n",
        "    y = sub_df[\"product_label\"]\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)\n",
        "    train_ds = ProductDataset(X_train.reset_index(drop=True), pd.Series(y_train).reset_index(drop=True), tokenizer)\n",
        "    val_ds = ProductDataset(X_val.reset_index(drop=True), pd.Series(y_val).reset_index(drop=True), tokenizer)\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Модель\n",
        "    model = E5ProductClassifier(MODEL_NAME, len(le.classes_)).to(DEVICE)\n",
        "    optimizer = Adam(model.parameters(), lr=2e-5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch in tqdm(train_loader, desc=f\"{category} | Epoch {epoch+1}\"):\n",
        "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "            labels = batch[\"labels\"].to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(input_ids, attention_mask), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1} loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # Оценка\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            logits = model(batch[\"input_ids\"].to(DEVICE), batch[\"attention_mask\"].to(DEVICE))\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
        "\n",
        "    real_labels = sorted(list(set(all_labels)))\n",
        "    target_names = [le.classes_[i] for i in real_labels]\n",
        "\n",
        "    print(\"\\n=== Classification Report (обычная модель) ===\")\n",
        "    print(classification_report(all_labels, all_preds, labels=real_labels, target_names=target_names, zero_division=0))\n",
        "\n",
        "    # === Экспорт в ONNX и квантизация ===\n",
        "    print(f\"Квантизация модели для категории: {category}\")\n",
        "    model_cpu = model.to(\"cpu\").eval()\n",
        "    dummy_inputs = tokenizer(\"Пример текста\", return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=256)\n",
        "    onnx_path = os.path.join(category_dir, \"model.onnx\")\n",
        "\n",
        "    torch.onnx.export(\n",
        "        model_cpu,\n",
        "        (dummy_inputs[\"input_ids\"], dummy_inputs[\"attention_mask\"]),\n",
        "        onnx_path,\n",
        "        input_names=[\"input_ids\", \"attention_mask\"],\n",
        "        output_names=[\"logits\"],\n",
        "        dynamic_axes={\"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
        "                      \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
        "                      \"logits\": {0: \"batch_size\"}},\n",
        "        opset_version=17\n",
        "    )\n",
        "\n",
        "    # Квантизация ONNX-модели\n",
        "    quantized_onnx_path = os.path.join(category_dir, \"model_quantized.onnx\")\n",
        "    quantize_dynamic(\n",
        "        model_input=onnx_path,\n",
        "        model_output=quantized_onnx_path,\n",
        "        weight_type=QuantType.QInt8\n",
        "    )\n",
        "    print(f\"ONNX-квантизированная модель сохранена в {quantized_onnx_path}\")\n",
        "\n",
        "    # Очистка ненужного файла\n",
        "    os.remove(onnx_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
